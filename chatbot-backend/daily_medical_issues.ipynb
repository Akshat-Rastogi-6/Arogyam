{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_parquet('data/daily.parquet', engine='pyarrow')\n",
    "# df.to_json('data/daily.json',orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a highly knowledgeable and responsible AI doctor designed to analyze symptoms and provide general health guidance. Your primary role is to help users assess whether their symptoms require a consultation with a medical professional.\"\n",
    "            \"You should:\"\n",
    "            \"Ask clarifying questions to understand the symptoms better.\"\n",
    "            \"Provide general health advice based on common medical knowledge.\"\n",
    "            \"Identify lifestyle habits or behaviors that may contribute to discomfort and suggest changes.\"\n",
    "            \"Never suggest specific medications, treatments, or dosages.\"\n",
    "            \"If symptoms are severe, unusual, or persistent, strongly recommend consulting a medical professional.\"\n",
    "            \"Avoid diagnosing medical conditions definitivelyâ€”frame responses as guidance rather than medical conclusions.\"\n",
    "            \"Use a calm, reassuring, and professional tone to make users feel at ease.\"\n",
    "            \"Your goal is to empower users with knowledge about their symptoms while ensuring they seek professional help when necessary.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def input_func(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", input_func)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical_meadow_health_advise\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return [entry['input'] + \" \" + entry['output'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the Data\n",
    "def chunk_data(data):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(\"\\n\".join(data))\n",
    "    with open('data/chunks/high_fi.pkl', 'wb') as f:\n",
    "        pickle.dump(chunks, f)\n",
    "    return chunks\n",
    "\n",
    "# Generate Embeddings\n",
    "def embed(chunks):\n",
    "    result = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=chunks\n",
    "    )\n",
    "    tensor = torch.tensor(result['embedding'], dtype=torch.float32)\n",
    "    return tensor\n",
    "\n",
    "# Store Embeddings in FAISS\n",
    "def store_embeddings(tensor):\n",
    "    embeddings = np.array([embedding.cpu().numpy() for embedding in tensor])\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, \"data/vectors/high_fi.faiss\")\n",
    "    return index\n",
    "\n",
    "# Search for Relevant Chunks\n",
    "def search_embeddings(query_embedding, chunks, k=3):\n",
    "    query_embedding_array = np.expand_dims(np.array(query_embedding, dtype='float32'), axis=0)\n",
    "    index = faiss.read_index(\"data/vectors/high_fi.faiss\")\n",
    "    distances, indices = index.search(query_embedding_array, k)\n",
    "    matching_chunks = [chunks[i] for i in indices[0]]\n",
    "    return matching_chunks\n",
    "\n",
    "# Generate Response\n",
    "def generate_response(matching_chunks, query, app):\n",
    "    context = \"\\n\".join(matching_chunks)\n",
    "    # print(\"Context:\\n\", context)\n",
    "    input_prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    input_message = [HumanMessage(content=input_prompt)]\n",
    "    output = app.invoke({\"messages\": input_message}, config)\n",
    "    return output[\"messages\"][-1].content\n",
    "\n",
    "# Analyze JSON Data\n",
    "def analyze_json(json_file):\n",
    "    data = load_json(json_file)\n",
    "    print(\"file loaded\")\n",
    "    chunked = chunk_data(data)\n",
    "    print(\"Chunked\")\n",
    "    # chunked = pickle.load(open('data\\chunks\\high_fi.pkl', 'rb'))\n",
    "    # print(\"chunks loaded\")\n",
    "    embeddings = embed(chunked)\n",
    "    print(\"Embedded\")\n",
    "    store_embeddings(embeddings)\n",
    "    print(\"Embedding saved\")\n",
    "    # query_embedding = embed(query)\n",
    "    # results = search_embeddings(query_embedding, chunked)\n",
    "    # response = generate_response(results, query, app)\n",
    "    # return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded\n",
      "Chunked\n",
      "Embedded\n",
      "Embedding saved\n"
     ]
    }
   ],
   "source": [
    "json_file = \"data\\medical_meadow_health_advice.json\"\n",
    "ans = analyze_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am coughing a lot for more than one week. What should I do?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membed\u001b[49m(query)\n\u001b[0;32m      3\u001b[0m chunked \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhigh_fi.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m search_embeddings(query_embedding, chunked)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embed' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"I am coughing a lot for more than one week. What should I do?\"\n",
    "query_embedding = embed(query)\n",
    "chunked = pickle.load(open('data\\chunks\\high_fi.pkl', 'rb'))\n",
    "results = search_embeddings(query_embedding, chunked)\n",
    "response = generate_response(results, query, app)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      " Whenever I have a really good laugh I end up coughing to the point that I have trouble catching my breath and taste blood. The cough usually last for several hours, and it happens every single time I get a good laugh. It has literally gotten to the point where my friends have started to warn me\n",
      "I have a problem with severe dry cough attacks that seem to be triggered from sudden temperature changes and sometimes when eating. By temperature change I mean when I get in a cool vehicle when its hot outside is one example I have experienced. I have these attacks 3 or 4 times a day. There is\n",
      "Hello Sir, I have dry cough problem since 1.5 months i consult many doctors but not diagnose very well and still suffer from this problem.I got cough after eating any meal and it continous whole day when i talk or take walk outside also so is there any serious problem Hello. Thank you for asking at\n"
     ]
    }
   ],
   "source": [
    "query = \"I have dry cough. It is severe. Laughing triggers it. \"\n",
    "query_embedding = embed(query)\n",
    "chunked = pickle.load(open('data\\chunks\\high_fi.pkl', 'rb'))\n",
    "results = search_embeddings(query_embedding, chunked)\n",
    "response = generate_response(results, query, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A severe dry cough triggered by laughing is unusual and warrants immediate medical attention.  The fact that you're experiencing coughing to the point of breathlessness and tasting blood is a serious concern.  This is not something that can be safely addressed without a proper medical evaluation.\n",
      "\n",
      "**Do not delay in seeking professional medical help.**  This symptom combination could indicate a variety of underlying issues that require prompt diagnosis and treatment.\n",
      "\n",
      "While I cannot speculate on the cause,  possible explanations could range from an underlying respiratory condition to a more serious issue.  Only a doctor can determine the cause through a thorough examination, potentially including imaging studies or other tests.\n",
      "\n",
      "**Please schedule an appointment with your doctor or go to an urgent care facility as soon as possible.**  This is not a condition to manage at home.  Your health and safety are paramount.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
